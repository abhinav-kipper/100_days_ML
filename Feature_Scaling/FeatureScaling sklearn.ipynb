{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=np.array([[1.,-1.,2.],\n",
    "          [2.,0.,0.],\n",
    "          [0.,1.,-1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         -1.22474487  1.33630621]\n",
      " [ 1.22474487  0.         -0.26726124]\n",
      " [-1.22474487  1.22474487 -1.06904497]]\n",
      "[ 0.  0.  0.]\n",
      "[ 1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "X_scaled=preprocessing.scale(X)\n",
    "#it makes mean to be 0 and variance to be 1 by default\n",
    "#can pass parameters to change default\n",
    "print(X_scaled)\n",
    "print(X_scaled.mean(axis=0))\n",
    "print(X_scaled.std(axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#scale xtrain and xtest together\n",
    "#coz otherwise xtrain will be scaled acc to its mean and train with its own other mean\n",
    "#so option 1 dont do it seperately\n",
    "#but in real scenarios we train .. test data comes from customer later on\n",
    "#so best way OPTION 2\n",
    "#scale on xtrain-----> store  the parameters on which scaling done(mean etc)\n",
    "#when testing data comes---->use same parameters for it\n",
    "for this use \n",
    "preprocessing.StandardScaler() #works same but returns object which can be further used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler=preprocessing.StandardScaler()\n",
    "scaler.fit(X) #object fitted \n",
    "#can use this object to transform anything using the same parameters\n",
    "\n",
    "scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  1.22474487, -0.26726124]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=[[1,1,0]] #need to give 2 d array -- as it hopes array of diff datapoints - here one\n",
    "scaler.transform(X_test) #scaled the data as per parameters learned while training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIN MAX SCALER\n",
    "MAX ABSOLUTE SCALER \n",
    "etc also available\n",
    "#All scalers take parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.]\n",
      "[ 1.06770783  1.50996689]\n",
      "0.0\n",
      "1.10994116266\n",
      "0.0\n",
      "8.87952930128\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data=[[0,3],[9,4],[2,7],[1,1]]\n",
    "Scaler=StandardScaler()\n",
    "Scaler.fit(data)\n",
    "first=Scaler.transform(data)\n",
    "second=Scaler.transform([[2,13],[1,4],[10,7],[1,9]])\n",
    "print(first.std(axis=0))\n",
    "print(second.std(axis=0))\n",
    "print(first.mean())\n",
    "#coz mean will change acc to more data previously mean was made 0\n",
    "#but for second it must  be according to first\n",
    "print(second.mean())\n",
    "print(first.sum())\n",
    "print(second.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
